{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-hub opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Resize image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.25)\n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1156/4030531585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mfr\"F:\\Ojas SSD\\Ojas\\Python\\Scienceexib\\Frames\\frame{x}.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Resize image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "cap = cv2.imread(fr\"F:\\Ojas SSD\\Ojas\\Python\\Scienceexib\\Frames\\frame{x}.jpg\")\n",
    "frame=cap\n",
    "    \n",
    "# Resize image\n",
    "img = frame.copy()\n",
    "img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "# Detection section\n",
    "results = movenet(input_img)\n",
    "keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "\n",
    "# Render keypoints \n",
    "loop_through_people(frame, keypoints_with_scores, EDGES, 0.22)\n",
    "while True:\n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "    if cv2.waitKey(10) & 0xFF==ord('n'):\n",
    "        break\n",
    "    \n",
    "cv2.imwrite(\"Hey.png\",frame)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.27003023, 0.30028734, 0.11083874],\n",
       "        [0.24188834, 0.32549033, 0.13397208],\n",
       "        [0.20620915, 0.3096327 , 0.15522145],\n",
       "        [0.24590789, 0.32197636, 0.1341855 ],\n",
       "        [0.17734155, 0.27784932, 0.15706302],\n",
       "        [0.31359065, 0.24004896, 0.10324387],\n",
       "        [0.2573926 , 0.20443778, 0.09732514],\n",
       "        [0.45238137, 0.25621995, 0.03155606],\n",
       "        [0.42702138, 0.15575382, 0.02433665],\n",
       "        [0.48738402, 0.24967527, 0.05952699],\n",
       "        [0.48233688, 0.16621605, 0.02065668],\n",
       "        [0.39090043, 0.10764223, 0.03569803],\n",
       "        [0.35443968, 0.04233905, 0.03422426],\n",
       "        [0.44158122, 0.1586245 , 0.09642186],\n",
       "        [0.45153326, 0.14394687, 0.09243739],\n",
       "        [0.44639644, 0.11272778, 0.02921812],\n",
       "        [0.40804225, 0.07409511, 0.02091025]],\n",
       "\n",
       "       [[0.15904874, 0.3768737 , 0.05138283],\n",
       "        [0.13875605, 0.38250974, 0.0791804 ],\n",
       "        [0.14922044, 0.37819988, 0.05803177],\n",
       "        [0.12395483, 0.40287772, 0.05720044],\n",
       "        [0.14968644, 0.3812305 , 0.04901163],\n",
       "        [0.14091808, 0.39415166, 0.05332103],\n",
       "        [0.13779233, 0.3833843 , 0.05982371],\n",
       "        [0.18388605, 0.4032708 , 0.04768052],\n",
       "        [0.1612074 , 0.37298727, 0.05319798],\n",
       "        [0.1692181 , 0.37583902, 0.02963373],\n",
       "        [0.1953437 , 0.33721825, 0.04807182],\n",
       "        [0.19208549, 0.4081854 , 0.07243257],\n",
       "        [0.19356444, 0.4005351 , 0.06488569],\n",
       "        [0.18884203, 0.36748695, 0.08151584],\n",
       "        [0.17933284, 0.35354218, 0.14516145],\n",
       "        [0.19488424, 0.33688182, 0.15247215],\n",
       "        [0.1931361 , 0.33272257, 0.12214004]],\n",
       "\n",
       "       [[0.3307369 , 0.25121227, 0.01299836],\n",
       "        [0.3240192 , 0.276993  , 0.01820752],\n",
       "        [0.28438646, 0.2516949 , 0.00401679],\n",
       "        [0.34573564, 0.27174518, 0.03271827],\n",
       "        [0.4083373 , 0.1624708 , 0.00357315],\n",
       "        [0.54010916, 0.24041128, 0.1973107 ],\n",
       "        [0.47331196, 0.07919983, 0.02149824],\n",
       "        [0.60522336, 0.22974901, 0.04900498],\n",
       "        [0.60897684, 0.02035312, 0.06880293],\n",
       "        [0.55027664, 0.19825426, 0.05882398],\n",
       "        [0.6085613 , 0.03743496, 0.0501799 ],\n",
       "        [0.7597856 , 0.131813  , 0.02788937],\n",
       "        [0.73187125, 0.04236245, 0.02710223],\n",
       "        [0.72299576, 0.15479808, 0.03629367],\n",
       "        [0.69958115, 0.06457632, 0.02128362],\n",
       "        [0.5807445 , 0.13005665, 0.02313353],\n",
       "        [0.5985016 , 0.10701348, 0.02777488]],\n",
       "\n",
       "       [[0.41774723, 0.38552624, 0.19880804],\n",
       "        [0.40068373, 0.39292106, 0.16354324],\n",
       "        [0.38263282, 0.38675153, 0.1258525 ],\n",
       "        [0.39413106, 0.3845199 , 0.16504829],\n",
       "        [0.3791872 , 0.36439407, 0.09640507],\n",
       "        [0.43412757, 0.37634584, 0.09943897],\n",
       "        [0.41630968, 0.3503512 , 0.03885862],\n",
       "        [0.48966083, 0.35453057, 0.01564794],\n",
       "        [0.43751186, 0.3107935 , 0.02916546],\n",
       "        [0.4417095 , 0.32740024, 0.02892878],\n",
       "        [0.43244886, 0.3109478 , 0.03068067],\n",
       "        [0.5530575 , 0.32862046, 0.00497946],\n",
       "        [0.5023689 , 0.31354412, 0.00509588],\n",
       "        [0.54401743, 0.34106097, 0.01509321],\n",
       "        [0.4846232 , 0.34540528, 0.01791801],\n",
       "        [0.56381744, 0.35381553, 0.00826123],\n",
       "        [0.53864646, 0.3413014 , 0.01100655]],\n",
       "\n",
       "       [[0.717608  , 0.83749247, 0.06999144],\n",
       "        [0.71802825, 0.8341174 , 0.03437327],\n",
       "        [0.7194943 , 0.83775246, 0.04685497],\n",
       "        [0.69819725, 0.8531305 , 0.03302086],\n",
       "        [0.7161338 , 0.84395427, 0.04313584],\n",
       "        [0.72493756, 0.84471685, 0.03403989],\n",
       "        [0.7180984 , 0.845319  , 0.15955451],\n",
       "        [0.7442094 , 0.8753719 , 0.0552712 ],\n",
       "        [0.74826384, 0.84325856, 0.15725648],\n",
       "        [0.7480442 , 0.85014564, 0.0396129 ],\n",
       "        [0.7623114 , 0.8421016 , 0.1564088 ],\n",
       "        [0.81411874, 0.835707  , 0.09250206],\n",
       "        [0.80446905, 0.837443  , 0.11858818],\n",
       "        [0.86559606, 0.8447415 , 0.05035128],\n",
       "        [0.8444983 , 0.8293273 , 0.06763988],\n",
       "        [0.8676445 , 0.84533405, 0.03252665],\n",
       "        [0.8698138 , 0.83256143, 0.086604  ]],\n",
       "\n",
       "       [[0.19637853, 0.30198425, 0.18816796],\n",
       "        [0.1893305 , 0.31269327, 0.16809483],\n",
       "        [0.17634675, 0.29682928, 0.35954422],\n",
       "        [0.20722237, 0.32993886, 0.10003529],\n",
       "        [0.1737723 , 0.2859025 , 0.25897515],\n",
       "        [0.18090451, 0.3249893 , 0.05897662],\n",
       "        [0.12989539, 0.28199264, 0.07748925],\n",
       "        [0.1966152 , 0.36108372, 0.03506263],\n",
       "        [0.14324811, 0.27200428, 0.06710029],\n",
       "        [0.19539979, 0.33514294, 0.04174233],\n",
       "        [0.16907367, 0.26863152, 0.08799909],\n",
       "        [0.1364489 , 0.3362542 , 0.05538097],\n",
       "        [0.12481475, 0.31729674, 0.04730652],\n",
       "        [0.15679257, 0.32533917, 0.0614949 ],\n",
       "        [0.1405316 , 0.31625065, 0.0687928 ],\n",
       "        [0.16516225, 0.2815887 , 0.11893941],\n",
       "        [0.15801904, 0.27619612, 0.07740016]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "beedbe2faf2f7048d727558d0bc3221e7eba2a0b921cac4d4771b2feb8f74b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
